{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Analysis in Social Media\n",
    "\n",
    "Leverage the newly published and labelled reddit dataset for stress analysis to develop and improve supervised learning methods for identifying stress, both neural and traditional, and analyze the complexity and diversity of the data and characteristics of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_preprocess import Posts\n",
    "from word_embedding_vectorizer import WordEmbeddingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/content/Insight_Stress_Analysis/data/' \n",
    "path = '../../data/'\n",
    "train = pd.read_csv(path + 'dreaddit-train.csv', encoding = \"ISO-8859-1\")\n",
    "test = pd.read_csv(path + 'dreaddit-test.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = Posts(train.text)\n",
    "test_text = Posts(test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gillianchiang/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 2838/2838 [00:00<00:00, 32353.68it/s]\n",
      "  0%|          | 6/2838 [00:00<00:48, 58.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1289/2838 [00:14<00:15, 98.88it/s] "
     ]
    }
   ],
   "source": [
    "train_text = train_text.preprocess()\n",
    "test_text = test_text.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(train_text, size=300, window=10, min_count=2, workers=10, iter=100)\n",
    "word_vectorizer = WordEmbeddingVectorizer(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = word_vectorizer.fit(train_text).transform(train_text)\n",
    "X_test = word_vectorizer.fit(test_text).transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.label\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "word_embedding_rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train) \n",
    "y_pred = word_embedding_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile word_embedding_model.py\n",
    "import pandas as pd\n",
    "import bentoml\n",
    "from bentoml.artifact import PickleArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "from data_preprocess import Posts\n",
    "from word_embedding_vectorizer import WordEmbeddingVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "@bentoml.artifacts([PickleArtifact('word_vectorizer'),\n",
    "                    PickleArtifact('word_embedding_rf')]) \n",
    "\n",
    "@bentoml.env(pip_dependencies=[\"pandas\", \"numpy\", \"gensim\", \"scikit-learn\", \"nltk\"])\n",
    "\n",
    "class WordEmbeddingModel(bentoml.BentoService):\n",
    "        \n",
    "    @bentoml.api(DataframeHandler, typ='series')\n",
    "    def data_preprocess(self, series):\n",
    "        preprocess_series = Posts(series).preprocess()\n",
    "        input_matrix = self.artifacts.word_vectorizer.fit(preprocess_series).transform(preprocess_series)\n",
    "        return input_matrix\n",
    "    \n",
    "    @bentoml.api(DataframeHandler, typ='series')\n",
    "    def predict(self, series):\n",
    "        input_matrix = self.data_preprocess(series)\n",
    "        pred_labels = self.artifacts.word_embedding_rf.predict(input_matrix)\n",
    "        pred_proba = self.artifacts.word_embedding_rf.predict_proba(input_matrix)\n",
    "        confidence_score = [prob[1] for prob in pred_proba]\n",
    "        output = pd.DataFrame({'text': series, 'confidence_score': confidence_score, 'labels': pred_labels})\n",
    "        output['labels'] = output['labels'].map({1: 'stress', 0: 'non-stress'})\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from word_embedding_rf_model import WordEmbeddingRFModel\n",
    "# Initialize bentoML model with artifacts\n",
    "\n",
    "bento_model = WordEmbeddingRFModel()\n",
    "bento_model.pack('word_vectorizer', word_vectorizer)\n",
    "bento_model.pack('word_embedding_rf', word_embedding_rf)\n",
    "\n",
    "# Save bentoML model to directory\n",
    "saved_path = bento_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the directory containing exported model archive (prefixed with model name and version)\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BentoService from saved bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "# Load exported bentoML model archive from path\n",
    "bento_model = bentoml.load(saved_path)\n",
    "\n",
    "# Call predict on the restored sklearn model\n",
    "series = test.text.iloc[:10]\n",
    "bento_model.predict(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_tag = '{name}:{version}'.format(name=bento_model.name, version=bento_model.version)\n",
    "bento_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy BentoService with Google Cloud Run\n",
    "Tutorial: https://github.com/bentoml/BentoML/blob/master/guides/deployment/deploy-with-google-cloud-run/deploy-with-google-cloud-run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
